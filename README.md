
![assets/logo.png](assets/logo.png)
 <h4 align="center">
    <p>
        <b>ä¸­æ–‡</b> | <a href="https://github.com/OpenBMB/UltraEval-Audio/blob/main/README_en.md">English</a> |
<a href="https://discord.gg/jKYuDc2M" target="_blank">ğŸ’¬discord</a>
 </h4>


# Overview

### ğŸš€è¶…å‡¡ä½“éªŒï¼Œå°½åœ¨UltraEval-AudioğŸš€

UltraEval-Audioâ€”â€”å…¨çƒé¦–ä¸ªåŒæ—¶æ”¯æŒè¯­éŸ³ç†è§£å’Œè¯­éŸ³ç”Ÿæˆè¯„ä¼°çš„å¼€æºæ¡†æ¶ï¼Œä¸“ä¸ºè¯­éŸ³å¤§æ¨¡å‹è¯„ä¼°æ‰“é€ ï¼Œé›†åˆäº†34é¡¹æƒå¨Benchmarkï¼Œè¦†ç›–è¯­éŸ³ã€å£°éŸ³ã€åŒ»ç–—åŠéŸ³ä¹å››å¤§é¢†åŸŸï¼Œæ”¯æŒåç§è¯­è¨€ï¼Œæ¶µç›–åäºŒç±»ä»»åŠ¡ã€‚é€‰æ‹©UltraEval-Audioï¼Œæ‚¨å°†ä½“éªŒåˆ°å‰æ‰€æœªæœ‰çš„ä¾¿æ·ä¸é«˜æ•ˆï¼š

- **ä¸€é”®å¼åŸºå‡†ç®¡ç† ğŸ“¥**ï¼šå‘Šåˆ«ç¹ççš„æ‰‹åŠ¨ä¸‹è½½ä¸æ•°æ®å¤„ç†ï¼ŒUltraEval-Audioä¸ºæ‚¨è‡ªåŠ¨åŒ–å®Œæˆè¿™ä¸€åˆ‡ï¼Œè½»æ¾è·å–æ‰€éœ€åŸºå‡†æµ‹è¯•æ•°æ®ã€‚
- **å†…ç½®è¯„ä¼°åˆ©å™¨ âš™ï¸**ï¼šæ— éœ€å†å››å¤„æœå¯»è¯„ä¼°å·¥å…·ï¼ŒUltraEval-Audioå†…ç½®å…«ç§å¸¸ç”¨çš„è¯„ä¼°æ–¹æ³•ï¼ˆå¦‚WERã€WER-ZHã€BLEUã€G-Evalï¼‰ï¼Œæ— è®ºæ˜¯åŸºäºè§„åˆ™è¿˜æ˜¯æ¨¡å‹é©±åŠ¨ï¼Œéƒ½èƒ½æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚
- **åŠŸèƒ½å¼ºå¤§ï¼Œçµæ´»æ˜“ç”¨ ğŸ› ï¸**ï¼šæ”¯æŒé¢„è§ˆæµ‹è¯•ã€éšæœºæ ·æœ¬ã€é”™è¯¯é‡è¯•ã€æ–­ç‚¹é‡è·‘ç­‰åŠŸèƒ½ï¼Œç¡®ä¿è¯„ä¼°è¿‡ç¨‹çµæ´»å¯æ§ï¼Œæå‡æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚
- **æ— ç¼é›†æˆè‡ªå®šä¹‰æ•°æ®é›† ğŸ’¼**ï¼šä¸ä»…æ”¯æŒå…¬å¼€benchmarkï¼Œè¿˜æä¾›å¼ºå¤§çš„è‡ªå®šä¹‰æ•°æ®é›†åŠŸèƒ½ï¼Œè®©æ‚¨åœ¨å„ç§å·¥ç¨‹åœºæ™¯ä¸‹ä¹Ÿèƒ½è¿…é€Ÿåº”ç”¨ã€‚
- **è½»æ¾å¯¹æ¥ç°æœ‰ç³»ç»Ÿ ğŸ”—**ï¼šå…·å¤‡ä¼˜ç§€çš„æ‰©å±•æ€§å’Œæ ‡å‡†åŒ–è®¾è®¡ï¼Œå³ä½¿æ‚¨å·²æ‹¥æœ‰ä¸€å¥—å®Œå–„çš„è¯„ä¼°ä½“ç³»ï¼ŒUltraEval-Audioä¹Ÿèƒ½æ— ç¼å¯¹æ¥ï¼Œç®€åŒ–é¡¹ç›®ç®¡ç†æµç¨‹ï¼Œè¾“å‡ºç»“æœç»Ÿä¸€è§„èŒƒã€‚

# Leaderboard

> **Audio Understanding LLM**: Speech + Text â†’ Text
>
> **Audio Generation LLM**: Speech â†’ Speech

<div style="display: flex;">
  <div style="flex: 1; margin-right: 10px;">

## Audio Understanding LLM Leaderboard


| Rank | Model                   | ASR | AST |
|------|-------------------------|-----|-----|
| ğŸ…   | MiniCPM-o 2.6           | 96  | 38  |
| ğŸ¥ˆ   | Gemini-1.5-Pro          | 94  | 35  |
| ğŸ¥‰   | qwen2-audio-instruction | 94  | 31  |
| 4    | GPT-4o-Realtime         | 92  | 26  |
| 5    | Gemini-1.5-Flash        | 49  | 21  |
| 6    | Qwen-Audio-Chat         | 3   | 12  |

  </div>
  <div style="flex: 1;">

## Audio Generation LLM Leaderboard

| Rank | Model           | Semantic | Acoustic | AudioArena |
|------|-----------------|----------|----------|------------|
| ğŸ…   | GPT-4o-Realtime | 67       | 84       | 1200       |
| ğŸ¥ˆ   | MiniCPM-o 2.6   | 48       | 80       | 1131       |
| ğŸ¥‰   | GLM-4-Voice     | 42       | 82       | 1035       |
| 4    | Mini-Omni       | 16       | 64       | 897        |
| 5    | Llama-Omni      | 29       | 54       | 875        |
| 6    | Moshi           | 27       | 68       | 865        |


</div>
</div>

> è¯¦ç»†æ¨¡å‹æŒ‡æ ‡è§[leaderboard.md](assets/leaderboard.md)


<table>
<tr>
<td><img src="assets/audio_understanding_leaderboard.png" alt="å›¾ç‰‡ 1 æè¿°"></td>
<td><img src="assets/s2s_leaderboard.png" alt="å›¾ç‰‡ 2 æè¿°"></td>
</tr>
</table>

    # æ”¯æŒæ•°æ®é›†

![assets/dataset_distribute.png](assets/dataset_distribute.png)
# æ›´æ–°æ—¥å¿—ğŸ”¥
- [2025/03/04]
  - æ”¯æŒæ–­ç‚¹[ç»­è¯„] [resume evaluation](docs/Procedures for Restarting an Incomplete Evaluation.md), å‘½ä»¤è¡Œå‚æ•° `--resume $checkpoint_res_file`
  - glm-4-voiceæœåŠ¡éƒ¨ç½²ï¼Œæ”¯æŒUltraEval-Audioè¯„æµ‹, è¯¦æƒ…è§[GLM-4-Voice](https://github.com/UltraEval/GLM-4-Voice)
  - å¹¶è¡Œè¯„æµ‹æ”¯æŒï¼Œå‘½ä»¤è¡Œå‚æ•° `--workers $num_workers`
- [2025/01/13] release v1.0.0



# å¿«é€Ÿä¸Šæ‰‹

## ç¯å¢ƒå‡†å¤‡
```shell
git clone https://github.com/OpenBMB/UltraEval-Audio.git
cd UltraEval-Audio
conda create -n aduioeval python=3.10 -y
conda activate aduioeval
pip install -r requirments.txt
```

## è¿è¡Œç¤ºä¾‹
```bash
export PYTHONPATH=$PWD:$PYTHONPATH

# é’ˆå¯¹éƒ¨åˆ†åœ°åŒºå¯èƒ½éœ€è¦åŠ é€Ÿä¸‹è½½ éœ€è¦è®¾ç½®ï¼šexport HF_ENDPOINT=https://hf-mirror.com
# æµ‹è¯•MiniCPM-o 2.6è¯­éŸ³ç†è§£èƒ½åŠ›
pip install -r requirments/minicpm_o2_6.txt
CUDA_VISIBLE_DEVICES=0 python audio_evals/main.py --dataset sample --prompt mini-cpm-omni-asr-zh --model MiniCPMo2_6-audio

# æµ‹è¯•MiniCPM-o 2.6è¯­éŸ³ç”Ÿæˆèƒ½åŠ›
CUDA_VISIBLE_DEVICES=0 python audio_evals/main.py --dataset llama-questions-s2t --model MiniCPMo2_6-speech

# æµ‹è¯•GPT-4o-Realtimeè¯­éŸ³ç†è§£èƒ½åŠ›
export OPENAI_API_KEY=$your-key
python audio_evals/main.py --dataset sample --model gpt4o_audio

# æµ‹è¯•GPT-4o-Realtimeè¯­éŸ³ç”Ÿæˆèƒ½åŠ›
export OPENAI_API_KEY=$your-key
python audio_evals/main.py --dataset llama-questions-s2t --model gpt4o_speech

# æµ‹è¯•gemini-1.5-proè¯­éŸ³ç†è§£èƒ½åŠ›
export GOOGLE_API_KEY=$your-key
python audio_evals/main.py --dataset sample --model gemini-pro


# æµ‹è¯•qwen2-audio-offlineè¯­éŸ³ç†è§£èƒ½åŠ›
pip install -r requirments-offline-model.txt
CUDA_VISIBLE_DEVICES=0 python audio_evals/main.py --dataset sample --model qwen2-audio-chat
```
é‡åˆ°æŠ¥é”™å¯ä»¥å…ˆçœ‹[å¸¸è§é—®é¢˜](FAQ.md)

## res

è¯„æµ‹å®Œæ¯•ï¼Œç»“æœæ–‡ä»¶å¦‚ä¸‹:

```txt
- res
    |-- $model-name
        |-- $dataset
            |-- $time.jsonl
            |-- $time-overview.jsonl
```


## Usage

![assets/img_1.png](assets/img_1.png)

è¯„æµ‹å‘½ä»¤:

```bash
python audio_evals/main.py --dataset <dataset_name> --model <model_name>
```

## æ•°æ®é›†é€‰æ‹©

`--dataset` æŒ‡å®šè¦è¯„æµ‹çš„æ•°æ®é›†ï¼Œæ”¯æŒçš„æ•°æ®é›†å¦‚ä¸‹:

- `speech-chatbot-alpaca-eval`
- `llama-questions`
- `speech-web-questions`
- `speech-triviaqa`
- `tedlium-release1`
- `tedlium-release2`
- `tedlium-release3`
- `catdog`
- `audiocaps`
- `covost2-en-ar`
- `covost2-en-ca`
- `covost2-en-cy`
- `covost2-en-de`
- `covost2-en-et`
- `covost2-en-fa`
- `covost2-en-id`
- `covost2-en-ja`
- `covost2-en-lv`
- `covost2-en-mn`
- `covost2-en-sl`
- `covost2-en-sv`
- `covost2-en-ta`
- `covost2-en-tr`
- `covost2-en-zh`
- `covost2-zh-en`
- `covost2-it-en`
- `covost2-fr-en`
- `covost2-es-en`
- `covost2-de-en`
- `GTZAN`
- `TESS`
- `nsynth`
- `meld-emo`
- `meld-sentiment`
- `clotho-aqa`
- `ravdess-emo`
- `ravdess-gender`
- `COVID-recognizer`
- `respiratory-crackles`
- `respiratory-wheezes`
- `KeSpeech`
- `audio-MNIST`
- `librispeech-test-clean`
- `librispeech-dev-clean`
- `librispeech-test-other`
- `librispeech-dev-other`
- `mls_dutch`
- `mls_french`
- `mls_german`
- `mls_italian`
- `mls_polish`
- `mls_portuguese`
- `mls_spanish`
- `heartbeat_sound`
- `vocalsound`
- `fleurs-zh`
- `voxceleb1`
- `voxceleb2`
- `chord-recognition`
- `wavcaps-audioset`
- `wavcaps-freesound`
- `wavcaps-soundbible`
- `air-foundation`
- `air-chat`
- `desed`
- `peoples-speech`
- `WenetSpeech-test-meeting`
- `WenetSpeech-test-net`
- `gigaspeech`
- `aishell-1`
- `cv-15-en`
- `cv-15-zh`
- `cv-15-fr`
- `cv-15-yue`


### æ•°æ®é›†è¯¦ç»†è¯´æ˜
| <dataset_name>             | name                       | task                              | domain             | metric     |
|----------------------------|----------------------------|-----------------------------------|--------------------|------------|
| speech-chatbot-alpaca-eval | speech-chatbot-alpaca-eval | SpeechQA                          | speech2speech      | GPT-score  |
| llama-questions            | llama-questions            | SpeechQA                          | speech2speech      | acc        |
| speech-web-questions       | speech-web-questions       | SpeechQA                          | speech2speech      | acc        |
| speech-triviaqa            | speech-triviaqa            | SpeechQA                          | speech2speech      | acc        |
| tedlium-*                  | tedlium                    | ASR(Automatic Speech Recognition) | speech             | wer        |
| clotho-aqa                 | ClothoAQA                  | AQA(AudioQA)                      | sound              | acc        |
| catdog                     | catdog                     | AQA                               | sound              | acc        |
| mls-*                      | multilingual_librispeech   | ASR                               | speech             | wer        |
| KeSpeech                   | KeSpeech                   | ASR                               | speech             | cer        |
| librispeech-*              | librispeech                | ASR                               | speech             | wer        |
| fleurs-*                   | FLEURS                     | ASR                               | speech             | wer        |
| aisheel1                   | AISHELL-1                  | ASR                               | speech             | wer        |
| WenetSpeech-*              | WenetSpeech                | ASR                               | speech             | wer        |
| covost2-*                  | covost2                    | STT(Speech Text Translation)      | speech             | BLEU       |
| GTZAN                      | GTZAN                      | MQA(MusicQA)                      | music              | acc        |
| TESS                       | TESS                       | EMO(emotional recognition)        | speech             | acc        |
| nsynth                     | nsynth                     | MQA                               | music              | acc        |
| meld-emo                   | meld                       | EMO                               | speech             | acc        |
| meld-sentiment             | meld                       | SEN(sentiment recognition)        | speech             | acc        |
| ravdess-emo                | ravdess                    | EMO                               | speech             | acc        |
| ravdess-gender             | ravdess                    | GEND(gender recognition)          | speech             | acc        |
| COVID-recognizer           | COVID                      | MedicineCls                       | medicine           | acc        |
| respiratory-*              | respiratory                | MedicineCls                       | medicine           | acc        |
| audio-MNIST                | audio-MNIST                | AQA                               | speech             | acc        |
| heartbeat_sound            | heartbeat                  | MedicineCls                       | medicine           | acc        |
| vocalsound                 | vocalsound                 | MedicineCls                       | medicine           | acc        |
| voxceleb*                  | voxceleb                   | GEND                              | speech             | acc        |
| chord-recognition          | chord                      | MQA                               | music              | acc        |
| wavcaps-*                  | wavcaps                    | AC(AudioCaption)                  | sound              | acc        |
| air-foundation             | AIR-BENCH                  | AC,GEND,MQA,EMO                   | sound,music,speech | acc        |
| air-chat                   | AIR-BENCH                  | AC,GEND,MQA,EMO                   | sound,music,speech | GPT4-score |
| desed                      | desed                      | AQA                               | sound              | acc        |
| peoples-speech             | peoples-speech             | ASR                               | speech             | wer        |
| gigaspeech                 | gigaspeech                 | ASR                               | speech             | wer        |
| cv-15-*                    | common voice 15            | ASR                               | speech             | wer        |

æ„é€ ä½ è‡ªå·±çš„æ•°æ®é›†: [docs/how add a dataset.md](docs%2Fhow%20add%20a%20dataset.md)


### æ¨¡å‹é€‰æ‹©

`--model` æŒ‡å®šè¦è¯„æµ‹çš„æ¨¡å‹ï¼Œæ”¯æŒçš„æ¨¡å‹å¦‚ä¸‹:

- **`gpt4o_audio`**ï¼šä½¿ç”¨ `gpt-4o-realtime-preview-2024-10-01` çš„éŸ³é¢‘è½¬æ–‡æœ¬æ¨¡æ€æ¨¡å‹ã€‚
- **`gpt4o_speech`**ï¼šä½¿ç”¨ `gpt-4o-realtime-preview-2024-10-01` çš„éŸ³é¢‘è½¬è¯­éŸ³æ¨¡æ€æ¨¡å‹ã€‚
- **`gpt4o_audio_ms`**ï¼šä½¿ç”¨ `gpt-4o-realtime-preview-2024-10-01`ï¼ˆåœ¨ AZURE ä¸Šï¼‰çš„éŸ³é¢‘è½¬æ–‡æœ¬æ¨¡æ€æ¨¡å‹ã€‚
- **`gpt4o_speech_ms`**ï¼šä½¿ç”¨ `gpt-4o-realtime-preview-2024-10-01`ï¼ˆåœ¨ AZURE ä¸Šï¼‰çš„éŸ³é¢‘è½¬è¯­éŸ³æ¨¡æ€æ¨¡å‹ã€‚
- **`gpt4o_speech`**ï¼šä½¿ç”¨ `Ggpt-4o-realtime-preview-2024-10-01` çš„éŸ³é¢‘è½¬è¯­éŸ³æ¨¡æ€æ¨¡å‹ã€‚
- **`gemini-pro`**ï¼šä½¿ç”¨ `Gemini Pro` æ¨¡å‹ã€‚
- **`gemini-1.5-pro`**ï¼šä½¿ç”¨ `Gemini 1.5 Pro` æ¨¡å‹ã€‚
- **`gemini-1.5-flash`**ï¼šä½¿ç”¨ `Gemini 1.5 Flash` æ¨¡å‹ã€‚
- **`gemini-2.0-flash-exp`**ï¼šä½¿ç”¨ `Gemini 2.0 Flash` æ¨¡å‹ã€‚
- **`qwen-audio`**ï¼šä½¿ç”¨ `qwen-audio-chat`  API æ¨¡å‹ã€‚
- **`qwen2-audio-offline`**ï¼šä½¿ç”¨ `Qwen2-Audio-7B` ç¦»çº¿æ¨¡å‹ã€‚
- **`qwen2-audio-chat`**ï¼šä½¿ç”¨ `Qwen2-Audio-7B-Instruct` ç¦»çº¿æ¨¡å‹ã€‚
- **`qwen-audio-chat-offline`**ï¼šä½¿ç”¨ `Qwen-Audio-Chat` ç¦»çº¿æ¨¡å‹ã€‚
- **`qwen-audio-pretrain-offline`**ï¼šä½¿ç”¨ `Qwen-Audio` ç¦»çº¿æ¨¡å‹ã€‚
- **`ultravox`**ï¼šä½¿ç”¨ `ultravox-v0_4` ç¦»çº¿æ¨¡å‹ã€‚

> speech2speech æ¨¡å‹(glm4voice,mini-omni...)ç¨åæ”¯æŒã€‚


è¯„æµ‹ä½ è‡ªå·±çš„æ¨¡å‹ [docs/how eval your model.md](docs%2Fhow%20eval%20your%20model.md)

# è‡´è°¢

æˆ‘ä»¬å‚è€ƒäº†[evals](https://github.com/openai/evals) ä¸­`registry`ä»£ç 

# è”ç³»æˆ‘ä»¬
å¦‚æœä½ æœ‰ä»»ä½•å»ºè®®æˆ–ç–‘é—®å¯ä»¥æissueæˆ–è€…åŠ å…¥discordç¾¤ç»„: https://discord.gg/PHGy66QP
