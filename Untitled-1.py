#!/usr/bin/env python3
import os
import argparse
import numpy as np
import torch
import soundfile as sf
from typing import Optional
import voxcpm
from datasets import load_dataset
from tqdm import tqdm


class VoxCPMInference:
    def __init__(self, model_dir: Optional[str] = None):
        """
        åˆå§‹åŒ– VoxCPM TTS æ¨ç†å™¨

        Args:
            model_dir: æ¨¡å‹ç›®å½•è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨è§£æ
        """
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")

        self.model_dir = model_dir or self._resolve_model_dir()
        print(f"ğŸ“ æ¨¡å‹ç›®å½•: {self.model_dir}")

        self.model = None
        self._load_model()

    def _load_model(self):
        """åŠ è½½ VoxCPM æ¨¡å‹"""
        try:
            print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
            self.model = voxcpm.VoxCPMModel.from_local(self.model_dir)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        except Exception as e:
            raise RuntimeError(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    def generate_speech(
        self,
        text: str,
        prompt_wav_path: Optional[str] = None,
        prompt_text: Optional[str] = None,
        cfg_value: float = 2.0,
        timesteps: int = 10,
        max_len: int = 1000,
        min_len: int = 10,
        output_path: Optional[str] = None,
        auto_save: bool = True,
    ) -> tuple[int, np.ndarray]:
        """
        ç”Ÿæˆè¯­éŸ³

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            prompt_wav_path: å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            prompt_text: å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
            cfg_value: CFG å€¼ï¼Œæ§åˆ¶ç”Ÿæˆè´¨é‡ (1.0-3.0)
            timesteps: æ¨ç†æ­¥æ•° (4-10)
            max_len: æœ€å¤§é•¿åº¦
            min_len: æœ€å°é•¿åº¦
            output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            auto_save: å¦‚æœä¸ºTrueä¸”æ²¡æœ‰æŒ‡å®šoutput_pathï¼Œå°†è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶åä¿å­˜

        Returns:
            tuple: (é‡‡æ ·ç‡, éŸ³é¢‘æ³¢å½¢æ•°æ®)
        """
        if not text or not text.strip():
            raise ValueError("âŒ è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬")

        text = text.strip()[:512]  # é™åˆ¶æ–‡æœ¬é•¿åº¦

        print(f"ğŸµ æ­£åœ¨ç”Ÿæˆè¯­éŸ³: '{text[:60]}{'...' if len(text) > 60 else ''}'")

        # ç”ŸæˆéŸ³é¢‘
        wav = self.model.generate(
            target_text=text,
            prompt_text=prompt_text or "",
            prompt_wav_path=prompt_wav_path or "",
            min_len=min_len,
            max_len=max_len,
            inference_timesteps=timesteps,
            cfg_value=cfg_value,
        )

        # è½¬æ¢ä¸º numpy æ•°ç»„
        if wav.dim() == 2:
            wav_np = wav.squeeze(0).numpy()
        else:
            wav_np = wav.numpy()

        sample_rate = self.model.sample_rate

        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        if output_path:
            self._save_audio(wav_np, sample_rate, output_path)
        return sample_rate, wav_np

    def _save_audio(self, wav_data: np.ndarray, sample_rate: int, output_path: str):
        """
        ä¿å­˜éŸ³é¢‘æ•°æ®åˆ°æ–‡ä»¶

        Args:
            wav_data: éŸ³é¢‘æ³¢å½¢æ•°æ®
            sample_rate: é‡‡æ ·ç‡
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir, exist_ok=True)

            # è§„èŒƒåŒ–éŸ³é¢‘æ•°æ®
            wav_data = np.clip(wav_data, -1.0, 1.0)

            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            sf.write(output_path, wav_data, sample_rate)

            # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸä¿å­˜
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path)
                duration = len(wav_data) / sample_rate
                print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {output_path}")
                print(f"   æ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
                print(f"   éŸ³é¢‘æ—¶é•¿: {duration:.2f} ç§’")
                print(f"   é‡‡æ ·ç‡: {sample_rate} Hz")
            else:
                print(f"âš ï¸  éŸ³é¢‘æ–‡ä»¶ä¿å­˜å¤±è´¥: {output_path}")

        except Exception as e:
            print(f"âŒ ä¿å­˜éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            # å°è¯•å¤‡ç”¨ä¿å­˜æ–¹æ³•
            try:
                import scipy.io.wavfile as wavfile

                # è½¬æ¢ä¸º16ä½æ•´æ•°æ ¼å¼
                wav_int16 = (wav_data * 32767).astype(np.int16)
                wavfile.write(output_path, sample_rate, wav_int16)
                print(f"ğŸ’¾ ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ä¿å­˜éŸ³é¢‘: {output_path}")
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨ä¿å­˜æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                raise RuntimeError(f"æ— æ³•ä¿å­˜éŸ³é¢‘æ–‡ä»¶: {output_path}")


def main():
    dataset_name = "/data/shiqundong/UltraEval-Audio/bosonai_EmergentTTS-Eval"
    dataset_hf = load_dataset(dataset_name, split="train")
    model_dir = (
        "/share_data/data11005/shiqundong/model/VoxCPM/VoxCPM-0.5B-20250831-stable"
    )
    try:
        # åˆå§‹åŒ–æ¨ç†å™¨
        inference = VoxCPMInference(model_dir=model_dir)

        for i in tqdm(range(len(dataset_hf))):
            row = dataset_hf[i]
            sample_rate, wav_data = inference.generate_speech(
                text=row["text_to_synthesize"], output_path=f"output/{i}.wav"
            )
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
